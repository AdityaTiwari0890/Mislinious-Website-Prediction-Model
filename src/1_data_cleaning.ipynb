{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8b9c525",
   "metadata": {},
   "source": [
    "# Data Cleaning for Malicious URL Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d37ed58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.parse import urlparse\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16934257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 shape: (651191, 2)\n",
      "Dataset 2 shape: (450176, 4)\n",
      "Dataset 1 columns: ['url', 'type']\n",
      "Dataset 2 columns: ['Unnamed: 0', 'url', 'label', 'result']\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "df1 = pd.read_csv('../malicious_phish.csv')\n",
    "df2 = pd.read_csv('../urldata.csv')\n",
    "\n",
    "print(\"Dataset 1 shape:\", df1.shape)\n",
    "print(\"Dataset 2 shape:\", df2.shape)\n",
    "print(\"Dataset 1 columns:\", df1.columns.tolist())\n",
    "print(\"Dataset 2 columns:\", df2.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8f661e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 type unique: ['phishing' 'benign' 'defacement' 'malware']\n",
      "df2 label unique: ['benign' 'malicious']\n",
      "df2 result unique: [0 1]\n",
      "df1 head:\n",
      "                                                  url        type\n",
      "0                                   br-icloud.com.br    phishing\n",
      "1                mp3raid.com/music/krizz_kaliko.html      benign\n",
      "2                    bopsecrets.org/rexroth/cr/1.htm      benign\n",
      "3  http://www.garage-pirenne.be/index.php?option=...  defacement\n",
      "4  http://adventure-nicaragua.net/index.php?optio...  defacement\n",
      "df2 head:\n",
      "    Unnamed: 0                        url   label  result\n",
      "0           0     https://www.google.com  benign       0\n",
      "1           1    https://www.youtube.com  benign       0\n",
      "2           2   https://www.facebook.com  benign       0\n",
      "3           3      https://www.baidu.com  benign       0\n",
      "4           4  https://www.wikipedia.org  benign       0\n"
     ]
    }
   ],
   "source": [
    "# Inspect datasets\n",
    "print(\"df1 type unique:\", df1['type'].unique())\n",
    "print(\"df2 label unique:\", df2['label'].unique())\n",
    "print(\"df2 result unique:\", df2['result'].unique())\n",
    "print(\"df1 head:\\n\", df1.head())\n",
    "print(\"df2 head:\\n\", df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e38a49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined df shape: (1101367, 2)\n",
      "Label distribution: label\n",
      "0    773841\n",
      "1    327526\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Standardize labels\n",
    "df1['label'] = df1['type'].map({'benign': 0, 'phishing': 1, 'defacement': 1, 'malware': 1})\n",
    "df2 = df2.drop(columns=['Unnamed: 0', 'label'])\n",
    "df2 = df2.rename(columns={'result': 'label'})\n",
    "\n",
    "# Combine datasets\n",
    "df = pd.concat([df1[['url', 'label']], df2[['url', 'label']]], ignore_index=True)\n",
    "\n",
    "print(\"Combined df shape:\", df.shape)\n",
    "print(\"Label distribution:\", df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b40251d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning shape: (627054, 2)\n",
      "Label distribution after cleaning: label\n",
      "0    381116\n",
      "1    245938\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning\n",
    "# Remove null URLs\n",
    "df = df.dropna(subset=['url'])\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates(subset=['url'])\n",
    "\n",
    "# Normalize URLs: lowercase, strip spaces\n",
    "df['url'] = df['url'].str.lower().str.strip()\n",
    "\n",
    "# Remove invalid URLs (basic check)\n",
    "def is_valid_url(url):\n",
    "    try:\n",
    "        result = urlparse(url)\n",
    "        return all([result.scheme, result.netloc])\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "df = df[df['url'].apply(is_valid_url)]\n",
    "\n",
    "print(\"After cleaning shape:\", df.shape)\n",
    "print(\"Label distribution after cleaning:\", df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a3bb75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aktiw\\AppData\\Local\\Temp\\ipykernel_15096\\3120301463.py:3: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_balanced = df.groupby('label').apply(lambda x: x.sample(min_count, random_state=42)).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced df shape: (491876, 2)\n",
      "Balanced label distribution: label\n",
      "0    245938\n",
      "1    245938\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Balance dataset\n",
    "min_count = df['label'].value_counts().min()\n",
    "df_balanced = df.groupby('label').apply(lambda x: x.sample(min_count, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "print(\"Balanced df shape:\", df_balanced.shape)\n",
    "print(\"Balanced label distribution:\", df_balanced['label'].value_counts())\n",
    "\n",
    "# Save cleaned data\n",
    "df_balanced.to_csv('../cleaned_urls.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
